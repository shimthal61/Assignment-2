---
title: "Assignment 2"
author: "Student ID: 10179889"
output:
  html_document:
    theme: flatly
    toc: true
    toc_float: true
    font-family: Lato
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Overview

For this assignment, we have been provided with three different datasets. Using the knowledge we have gained from the workshops combined with wider reading, I will:

-   Wrangle and tidy the data
-   Summarise the data
-   Visualise the data
-   Building and interpretting appropriate analyses

## Packages

First, let's load in our packages using the `library()` function:

```{r, message = FALSE, warning = FALSE}
library(tidyverse)
library(showtext)
library(afex)
library(emmeans)
library(visdat)
```

The `{tidyverse}` package contains a collection of open source R packages that gives us access to variety of useful functions and commands for data wrangling and visualisation. The `{showtext}` package enables us to load in, and use over 1291 fonts from [Google Fonts](https://fonts.google.com/) - useful for data visualisations. The `{afex}`and`{emmeans}` packages will allow us to build ANOVA models and perform and post-hoc analyses, respectively. We'll be using the `{afex]` package instead of the `{aov]` function in base R as it allows us to build ANOVA models that will work for our experimental designs, as well as using type III sums of squares by default. Finally, `{visdat}` will help us to spot any missing data in our datasets.

# Question 1

Let's read in our data and look over the question 1 information:

> <font size="3"> We have 96 participants in a between participants design where we are interested in the effect of visual quality of a word on response time to pronounce the word. Our experimental factor (visual quality) has 2 levels. These are Normal vs. Degraded, and Response Time is our DV measured on a continuous scale. Let's read in our data: </font>

```{r, message = FALSE}
raw_data_1 <- read_csv("assignment_2_dataset_1.csv")
head(raw_data_1)
```

## Data Wrangling

Our Visual Quality variable is currently just named "condition" - let's change it using the `rename()` function. Within the `mutate()` argument, we can also modify it so it's coded as a factor. Finally, our conditions are not labelled meaningfully and could lead to confusion further down the line. We can recode them using the `recode` command:

```{r, message = FALSE}
q1_data_tidied <- raw_data_1 %>%
  rename(visual_quality = condition) %>% 
  mutate(visual_quality = recode(visual_quality,
                            "condition_a" = "Normal",
                            "condition_b" = "Degraded")) %>% 
  mutate(visual_quality = factor(visual_quality))
head(q1_data_tidied)
```

We can check to see if we have missing data somewhere in our dataset. Using the package `{visdat}`, we can visualise our dataset using the `vis_dat()` function, which in turn will let us know if we have any missing data:

```{r}
vis_miss(q1_data_tidied)
```

It looks like all the data is present - no need to use the `na.rm = TRUE` function. Let's move on to generating summary statistics.

## Data Summarising

We'll first utilise the `group_by()` function to gather our visual-quality variable, then `summarise()` to create a new table comprising of response time mean and standard deviation. The data can be arranged from the fastest mean response time to the slowest using the `arrange()` function:

```{r, message = FALSE}
q1_data_tidied %>% 
  group_by(visual_quality) %>% 
  summarise(mean = mean(response_time), sd = sd(response_time)) %>% 
  arrange(mean)
```

At a glance, it looks as though participants who were presented a word with normal visual quality were faster at pronouncing the word than those who were presented with a word with degraded quality. At this stage, we can create some data visualisations to better convey our data.

## Data Visualisations

In this visualisation, we're jittering the data points, meaning that every time we execute the code, the points will jitter to a different position. This implies that our code is not reproducible, because we don't know the seed that R will use to generate the sequence. By setting the seed using the `set.seed()` function, we can ensure that the output will be the same every time it is ran. I set the seed to the number 42 for its reference to Hitch Hikers Guide to the Galaxy...

```{r}
set.seed(42)
```

To be able to manipulate the font family, we first need to download a font family from [Google Fonts](https://fonts.google.com). I decided to pick the 'Lato' Font, as its larger character height lends itself to easier readibility at small sizes. Let's read this font into R using the `font_add_()` command and tell `{showtext}` to automatically render the text:

```{r}
font_add("lato", regular = "lato-regular.ttf")
showtext_auto()
```

Next, we can build a visualisation by plotting the raw data points using the `geom_point` function, and the shape of the distribution for each condition using the `geom_violin()` function. By default, R will order the conditions alphabetically, so I used the `fct_relevel()` function to reorder the labels on the x-axis so that our 'normal' condition (the baseline) is on the left most side. We have also added some summary data in the form of the Mean and Confidence Intervals around the mean using the `stat_summary()` function. Finally, we can dictate the y-axis breaks within the `scale_y_continuous()` function, and change the text font and size within the `theme()` argument:

```{r, message = FALSE, warning = FALSE}
q1_data_tidied %>% 
  mutate(visual_quality = fct_relevel(visual_quality, "Normal", "Degraded")) %>% 
  ggplot(aes(x = visual_quality, y = response_time, colour = visual_quality)) +
  geom_violin(width = 0.3) +
  geom_point(alpha = 0.7, position = position_jitter(width = 0.08, seed = 42)) +
  theme_minimal() +
  stat_summary(fun.data = "mean_cl_boot", colour = "black") +
  guides(colour = 'none') +
  scale_y_continuous(breaks = seq(925, 1075, by = 25),
                     limits = c(925, 1075)) +
  labs(title = "Examining the effect of visual quality on response times",
       x = "Visual Quality",
       y = "Response Time (ms)") +
  theme(text = element_text(family = "Lato", size = 25))
```

## Building our ANOVA Model

Let's now build our model using the `aov_4()` function in the `{afex}` package. Within this package, the syntax for ANOVA models is: `aov_4(DV ~ IV + (1 | participant), data = q1_data_tidied)`. The `~` symbol translates to 'predicted by', and takes into account our random effect. We need to specify what data we are using in our model using `data = q1_data_tidied`. Finally, we map the output of the ANOVA result onto a variable I've called `between_anova`. This means that the ANOVA results will be stored in this variable and will allow us to access them later.

```{r, message=FALSE, warning = FALSE}
between_anova <- aov_4(response_time ~ visual_quality + (1 | participant), data = q1_data_tidied)
```

## Interpreting the Model Output

We can view the output of our new ANOVA model using the `anova()` function:

```{r}
anova(between_anova)
```

We can see that there is an effect in our model - the *p*-value is pretty small, but we don't yet know what direction this is in. Although we could refer to the condition means, I'm going to run a pairwise comparison using the `emmeans()` function. There is no need to change the adjustment, as we're not running multiple comparisons.

```{r}
emmeans(between_anova, pairwise ~ visual_quality)
```

An independent one-way ANOVA revealed a significant difference between IV level means, *F*(1,94) = 15.78, *p* \< .001, generalised η2 = .14. Tukey comparisons revealed that the normal visual quality group performed signficantly better than the degrated visual quality group (*p* \< .001)

In other words, participants were faster at pronouncing a word when the word was visually normal, compared to when the word was visually degraded.

# Question 2

First, we should read in our data and look over some of the characteristics of question 2:

> <font size="3"> We have 96 participants in a between participants design where we are interested in the effect of visual quality of a word on response time to pronounce the word. We are also interested in whether caffeine consumption will contribute to any of the variance. Our experimental factor (Visual Quality) has 2 levels. These are Normal vs. Degraded, and Response Time is our DV measured on a continuous scale. Caffiene Consumption is our covariate and has three levels - 1 cup, 2 cups, and 3 cups. We'll next read in our data: </font>

```{r, message=FALSE}
raw_data_2 <- read_csv("assignment_2_dataset_2.csv")
head(raw_data_2)
```

## Data Wrangling

Similar to before, we need to rename our 'condition' factor to 'visual_quality', code it as a factor, and name the conditions meaningfully:

```{r, message=FALSE}
q2_data_tidied <- raw_data_2 %>% 
  rename(visual_quality = condition) %>% 
  mutate(visual_quality = recode(visual_quality,
                                 "condition_a" = "Normal",
                                 "condition_b" = "Degreaded")) %>%
  mutate(visual_quality = factor(visual_quality))
head(q2_data_tidied)
```

## Data Visualising

Let's now have a look at the relationship between our experimental factor (Visual Quality), covariate (Caffeine Consumption), and our dependent variable (Response Time).

```{r, message = FALSE, warning=FALSE}
q2_data_tidied %>%
  mutate(visual_quality = fct_relevel(visual_quality, "Normal", "Degraded")) %>% 
  ggplot(aes(x = caffeine, y = response_time, colour = visual_quality)) +
  geom_smooth(aes(x = caffeine, y = response_time), inherit.aes = FALSE,
              method = "lm", se = FALSE) +
  geom_point(size = 1.5, position = position_jitter(width = 0.08, seed = 42)) +
  theme_minimal() +
  labs(x = "Cups of coffee",
       y = "Response Time (ms)",
       colour = "Visual Quality") +
  scale_y_continuous(breaks = seq(950, 1075, by = 25),
                     limits = c(950, 1075)) +
  theme(text = element_text(family = "lato", size = 25))
```

In this visualisation, I have added in a regression line that depicts the correlation between our covariant, Caffeine, and our DV, Response Time, using the `geom_smooth()` function. In our `geom_smooth` command, I was able to remove our experimental factor, Visual Quality, from the regression line by specifying what data to include using the `aes()` function, and for this data to supersede our graph aesthetics using `inherit.aes = FALSE`.

We can see from our regression line that there isn't a particularly strong relationship between Caffeine and Response Time. Interestingly, our Caffeine consumption groups appear to be clustering in our data by Visual Quality, suggesting that that our covaraite may have an effect on the relationship between Visual Quality and Caffeine. Let's build an ANCOVA model to test this assumption.

## Building our ANCOVA Model

We saw in our first dataset that Visual Quality had a significant effect on Response Time, with participants who were presented with visually normal words pronouncing them quicker than participants who were presented with visually degraded words. However, let's control for the effect of our covariate by building an ANCOVA model which includes Caffeine, ensuring that we add our covariate before our experimental condition manipulation. We set the factorize parameter to FALSE so that Caffeine is treated as a continuous predictor, rather than an experimental factor in our model.

```{r, message=FALSE, warning=FALSE}
model_ancova <- aov_4(response_time ~ caffeine + visual_quality + (1 | participant), data = q2_data_tidied, factorize = FALSE)
anova(model_ancova)
```

Now, when we control the effect of our covariate (Caffiene), we can see that the effect of Visual Quality, that previously was *F* = 15.78, is now *F* = 3.57, with *p* = .062 and is no longer significant. Moreover, as we predicted in our visualisation, our covariate is also non-significant, *F* = 1.12, *p* = .293. Following on from this, we can use the `emmeans()` function to produce the adjusted means for each of our two experimental groups, taking into account the influence of our covariate. I will also perform an unadjusted marginal means test without the covariate as I did in question 1 so that we can compare them.

**Unadjusted means**

```{r}
emmeans(between_anova, pairwise ~ visual_quality)
```

**Adjusted means**

```{r}
emmeans(model_ancova, pairwise ~ visual_quality)
```

We can see that our adjusted means differ from our unadjusted means for our experimental groups, although this difference is fairly small. Furthermore, our two adjusted means are still fairly far apart (normal = 1005ms, degraded = 1018ms), and can probably attribute to why our *p* value (*p* = .062) was very close to the significance threshold of .05.

## ANO(C)OVA as a Special Case of Regression

We are now going to look at AN(C)OVA as a special case of regression, building the equivalent linear models and interpreting the outputs.

### Setting up our contrasts

We first need to use dummy (treatment) data for the levels of our experimental factor. Let's have a look at our contrasts using the `contrasts()` function.

```{r}
contrasts(q2_data_tidied$visual_quality)
```

As it currently stands, our 'Degraded' condition is set at our reference level (0). However, it makes more sense for our 'Normal' group to be the reference level, as we want it to correspond to the intercept of our linear model. By default, R will generate a contrast matrix in alphabetical order, so we need to tell it otherwise. Similar to what we did in our visualisations, we can code the 'Normal' group as '0' using the `fct_relevel()` function:

```{r}
q2_data_tidied <- q2_data_tidied %>% 
  mutate(visual_quality = fct_relevel(visual_quality,
                                      c("Normal", "Degraded")))
contrasts(q2_data_tidied$visual_quality)
```

This is better - our 'Normal' condition is coded as '0' and now represents the reference level.

### ANOVA as a Linear Model

To make sense of our ANOVA as a Linear Model, we can use the equation of the general linear model.

`Response Time = Intercept + β1(Degraded)`

The intercept is our reference category (Normal) with coding (0), while the coding for 'Degraded' is (1). When we build our linear model, we'll be able to calculate the coefficients using this equation.

```{r}
anova_lm <- lm(response_time ~ visual_quality, data = q2_data_tidied)
```

Using the `lm()` function to build our linear model, we are asking for our DV, Response Time, to be predicted by our experimental factor, Visual Quality. Let's now call for the output of our model, which I've mapped to a variable called `anova_lm`:

```{r}
anova_lm
```

The intercept is 1002.22 (which is the mean for our 'Normal' group), and β1 is 18.09. We can now use this coefficiants alongside our equation to calcualate the averages for our 'Degraded' condition. I am using the `round()` function to round our intercept and coefficient means to the nearest integer, as this is what our `emmeans()` function does.

`Response Time = Intercept + β1(Degraded)`

```{r}
round(1002.22 + (18.09*1))
```

This output is the same as the mean Response Time that we calculated earlier for out 'Degraded' condition. By building our linear model and using the appropiate coding scheme, we have been able to generate exactly the same means as our ANOVA. This illustrates how ANOVA is a special case of regression and uses the linear model.

### ANCOVA as a Linear Model

We can also look at our ANCOVA as a case of regression. To do this, we simply add the covariate (Caffeine Consumption) to our model specification, making sure that it precedes our experimental factor.

```{r}
ancova_lm <- lm(response_time ~ caffeine + visual_quality, data = q2_data_tidied)
ancova_lm
```

In our output, we have our intercept and our coefficient means. We can check these adjusted against our previous ANCOVA model. Since Caffeine Consumption is not a factor we need to find out the mean of this variable using the `mean()` function:

```{r}
mean(q2_data_tidied$caffeine)
```

We add this mean (2.552083) to our equation together with the coefficients for each of our predictors. With our dummy coding scheme, we can work out the adjusted mean for our 'Normal' and 'Degraded' group. Again, I'm using the `round()` function to round the output to the nearest integer.

`Response Time = Intercept + β1(Caffeine) + β2(Degraded)`

**Normal Adjusted Mean**

```{r}
round(1011.354 + (2.469*2.552083) + (-12.791*0))
```

**Degraded Adjusted Mean**

```{r}
round(1011.354 + (2.469*2.552083) + (-12.791*1))
```

As we predicted, these adjusted means are the same as the means we saw earlier when building out ANCOVA model, and again demonstrates how ANCOVA is a special case of regression.

## Centering our Covariate

We can improve the interpretation of the coefficients in our linear model by scaling and centering our covariates. With out mean centrerd on 0, this standadises the variable and eliminates the need to multiply the linear model coefficient for the covariant by the covariate's mean.

By using the `scale()` function, we can create a scaled and centred version of our covariate in our data frame.

```{r}
q2_scaled_data <- q2_data_tidied %>% 
  mutate(centred_caffeine = scale(caffeine))
```

We can compare the uncentred to the centered covariate using the `plot()` function to see that the data is unchanged, other than the variable mean now being centered on zero and the distribution being scaled.

**Uncentered covariate**

```{r}
plot(density(q2_scaled_data$caffeine))
```

**Centered covariate**

```{r}
plot(density(q2_scaled_data$centred_caffeine))
```

Finally, let's build our linear model with the scaled and centered covariate.

```{r}
q2_ancova_centred <- lm(response_time ~ centred_caffeine + visual_quality, data = q2_scaled_data)
q2_ancova_centred      
```

The intercept now corresponds to the adjusted mean for the 'Normal' group. We can calculate the adjusted mean for the 'Degraded' group by subtracting 12.791 from 1017.655, and rounding the output. Therefore, scaling and centering the covariate makes it much easier to later interpret the coefficients of our linear model.

# Question 3

For our final question, let's have a look at the experiment we've been given and read in our data:

> <font size="3"> We have 148 participants in a 2 x 2 repeated measures design. We are interested in whether people respond faster to positive images following a positive prime (relative to following a negative prime), and faster to negative images following a negative prime (relative to following a positive prime). Two independent variables were manipulated within-participants in a fully factorial design; prime image with two levels (positive and negative) and target image with two levels (positive and negative). The time it took for participants to respond to the image, which was taken as a measure of reaction time, served as the dependent variable. </font>

```{r}
raw_data_3 <- read_csv("assignment_2_dataset_3.csv")
head(raw_data_3)
```

## Data Wrangling

Our data is currently in wider format, meaning that each row represents one participant. Instead, we want each row to represent the data from each condition from individual participants. To do this, we can lengthen the data using the `pivot_longer()` function.

```{r}
longer_data <- raw_data_3 %>% 
  pivot_longer(cols = c(positiveprime_positivetarget, positiveprime_negativetarget,
                        negativeprime_positivetarget, negativeprime_negativetarget),
               names_to = "Condition",
               values_to = "RT")
head(longer_data)
```

Our variables and conditions are still not labelled meaningfully - we can rename them using the `recode()` function. We also need to separate our 'Condition' variable and name them according to our independent variables so our tibble reflects the 2 x 2 structure of the experiment. Finally, we'll recode our IVs as factors:

```{r}
q3_data_tidied <- longer_data %>% 
  mutate(Condition = recode(Condition,
         "positiveprime_positivetarget" = "Positive_Positive",
         "positiveprime_negativetarget" = "Positive_Negative",
         "negativeprime_positivetarget" = "Negative_Positive",
         "negativeprime_negativetarget" = "Negative_Negative")) %>% 
  separate(col = "Condition", into = c("Prime", "Target"), sep = "_") %>% 
  mutate(Prime = factor(Prime), Target = factor(Target))
head(q3_data_tidied)
```

## Data Summarising

Let's generate some summary statistics and arrange the data from the fastest mean reaction time to the slowest. We need to specify our two grouping variables in the `group()` function call.

```{r}
q3_data_tidied %>% 
  group_by(Prime, Target) %>% 
  summarise(mean_RT = mean(RT), sd_RT = sd(RT)) %>% 
  arrange(mean_RT)
```

Looking at the tibble, it seems like participants were quickest at identifying the image when the prime valence was congruent with the target valence. As before, our output has not generated any missing data, so no need to run the `vis_miss()` function. Let's generate some data visualisations next.

## Data Visualisations



```{r}
q3_data_tidied %>% 
  ggplot(aes(x = Prime:Target, y = RT, colour = Prime:Target)) +
  geom_violin(width = .5) +
  geom_point(alpha = 0.7, position = position_jitter(width = 0.08, seed = 42)) +
  theme_minimal() +
  labs(x = y = "Reaction Time (ms)") +
  guides(colour = 'none') +
  theme(text = element_text(size = 13)) +
  scale_y_continuous(breaks = seq(1400, 1750, by = 50),
                     limits = c(1400, 1750))
```

